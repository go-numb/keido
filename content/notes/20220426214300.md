+++
title = "📝Clojure Scraping"
lastmod = 2022-09-12T08:29:53+09:00
tags = ["WIKI"]
draft = false
+++

Clojureによるスクレイピング技術まとめ.

-   up: [📁Clojure Development]({{< relref "20220211141917.md" >}})
-   refs:
    -   [📝Clojure string]({{< relref "20220428163355.md" >}})
    -   [📝Clojure Bot Development]({{< relref "20220721133610.md" >}})
        -   定期実行してクローラー化する話題はこっち.
    -   [🏷scraping]({{< relref "20211213184505.md" >}})


## Cljure Scraping Basic {#60581b}

いろいろとしらべると, HTTPクライアント(http-kit or clj-http) + enliveが王道. [enlive](https://github.com/cgrand/enlive) はClojureにおけるHTML parserの筆頭. HTTPクライアントのGet RequestでHTMLデータを取得してあとはゴリゴリ解析すればいい.

スクレイピングにClojureを選択する利点は,

-   Lispはそもそもparser処理に強い.
-   REPLによるインタラクティブな解析.
-   defaultでパラレルな処理に長けている.

つまりライブラリがなくともデフォルトで強い. いざとなればJavaのライブラリが使える([playwright]({{< relref "20211213184325.md" >}}) とか).

---

基本的には以下の流れだ.

-   url指定で get requestでHTMLの素のデータを取得.
-   enliveでhtmlデータをHashMapに変換.
-   defでREPLにbinding(キャッシュする).
-   キャッシュしたHashMapに対するパーサーをREPLと対話しながら作成.


## enlive-html {#d8f5eea6-7989-4f56-a689-1cb5cabc6360}

ref:  [Getting started · cgrand/enlive Wiki](https://github.com/cgrand/enlive/wiki/Getting-started)

[enlive](https://github.com/cgrand/enlive) はClojureにおけるテンプレートエンジンであるが, その中でもenlive-htmlがCSS-baseパーサーライブラリ.

```clojure
(require '[net.cgrand.enlive-html :as html])
```

**html-resource** で URLに対してget requestをしてbodyをtreeデータ(hash-maps)にパースしてくれる. もしくは, 自前でhttp getしてbodyを **html-snipet** に突っ込んでもい.

```clojure
(html/html-resource (java.net.URL url))
```

そしてこのデータは単なるClojureのhash-mapに過ぎないので，素のClojure関数でゴリゴリ中をみれるわけだ. **clojure.pprint/pprint** なんかでREPLに出力できる(HTMLデータが大きいときは注意).

enliveには **select** という関数があり, これでCSSセレクタを指定してアクセスできる. **get-in** のようにアクセス可能.


## enlive select Idioms {#0b3daa}

enliveのよくあるパターンの例まとめ. [🏷cljidiom]({{< relref "20220302101805.md" >}})

ref. [Enlive selectors syntax - GitHub](https://github.com/cgrand/enlive/wiki/Enlive-selectors-syntax)


### タイトル取得 {#e62ad7}

```clojure
;; title取得
(html/select [:title])

;; head取得
(html/select [:head])
```


### 特定のタグ {#cfc235}

大抵, **:hogehoge** で取れる. たとえば videoのようなタグは

```clojure
(html/select [:video])
```


### name属性取得 {#eb6f75}

name="description"という属性をもつ要素を取得.

```clojure
(html/select page [(html/attr= :name "description")])
```


### a tagのhrefの中身を取得 {#9a8bf4}

:a でアクセス. a.xxxだとclass:xxxをオプションで追加.

パースに取得成功すると [:atters :href]にurlがあるのでこれをMap操作で取得すればいい.


## Clojure Scraping Topics {#ee7938}


### 💡REPL上でゴニョゴニョパーサーをかける {#09223364-b4c1-4e09-9984-b0afb95da776}

結局HTMLを取得してそれをMapデータ構造とみなしてそれに対するパーサーを書くのがスクレイピングのキモだとすると, REPLで対話しながら欲しい情報を抜き出す処理をいろいろ試しながらできるのはとても強い.

[📝Clojure REPL駆動開発]({{< relref "20220117205249.md" >}})と大変相性がいいのがスクレイピングだ.


### 💡Lazy Sequence + pmap + doallの並列スクレイピングが強い {#ec1f1d43-00b8-4eaa-9bb7-751fbb843c9d}

複数ページにまたがるような処理だったり, offsetを指定してAPIを呼び出す時の並列スクレイピングが強い.

具体的にはページごとのスクレイピングの処理をpmapで遅延シーケンスに詰め込み, doallで実行することによってAPIを並列で発射刷ることが可能.

スクレイピングの並列化について各言語で実装は可能なもののClojureのこの気軽さはとても強い.

たくさんのページのスクレイピングに時間がかかるなあとかいっている並行プログラミングができない駆け出しエンジニアは情弱である.

[clojure pmap]({{< relref "20220116080205.md#0179abc5-0b84-49fb-9b4d-50e01e561e3a" >}})


## References {#d95867}

-   [Web Scraping with Clojure - Abu Ashraf Masnun](https://masnun.com/2016/03/20/web-scraping-with-clojure.html)
-   [Practicalli: Web Scraping with Clojure - Scraping Hacker News](https://practical.li/blog/posts/web-scraping-with-clojure-hacking-hacker-news/)
